
üìà Assistente de An√°lise de Neg√≥cios com Gemini e Streamlit
Uma aplica√ß√£o web interativa que utiliza a API do Google Gemini para atuar como um assistente de neg√≥cios, analisando an√∫ncios de oportunidades de investimento em tempo real. A interface √© constru√≠da com Streamlit e o projeto est√° estruturado para ser modular, escal√°vel e pronto para deploy.

(Lembre-se de substituir o link acima pelo URL do seu reposit√≥rio no GitHub)

(Recomendo tirar um screenshot da sua aplica√ß√£o a funcionar e colocar o link aqui)

‚ú® Funcionalidades Principais
Interface de Chat Interativa: Constru√≠da com Streamlit para uma experi√™ncia de utilizador fluida e moderna.

An√°lise por IA: Integra√ß√£o com a API do Google Gemini para fornecer an√°lises inteligentes sobre oportunidades de neg√≥cio.

Dados em Tempo Real: Recolhe e analisa dados ao vivo de fontes externas (atualmente configurado para uma API GraphQL do OLX).

Visualiza√ß√£o de Dados: Exibe os an√∫ncios encontrados numa barra lateral organizada, com imagens, pre√ßos e localiza√ß√µes.

Estrutura Modular: O c√≥digo √© dividido em m√≥dulos para UI, servi√ßos de API e configura√ß√£o, facilitando a manuten√ß√£o e expans√£o.

Pronto para Deploy: Inclui configura√ß√£o para deploy na Vercel, com gest√£o segura de chaves de API atrav√©s de vari√°veis de ambiente.

üõ†Ô∏è Tecnologias Utilizadas
Backend: Python 3.9+

Intelig√™ncia Artificial: Google Gemini API (google-generativeai)

Interface Web: Streamlit

Requisi√ß√µes HTTP: Requests

Manipula√ß√£o de Dados: Pandas

Deploy: Vercel

üìÇ Estrutura do Projeto
O projeto √© organizado de forma modular para separar as responsabilidades:

assistente_financeiro/
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ secrets.toml      # Chaves de API para desenvolvimento local
‚îú‚îÄ‚îÄ app.py                # Ficheiro principal que executa a UI do Streamlit
‚îú‚îÄ‚îÄ app_ui.py             # Fun√ß√µes respons√°veis por construir a UI
‚îú‚îÄ‚îÄ config.py             # Gest√£o de configura√ß√£o e chaves de API
‚îú‚îÄ‚îÄ gemini_service.py     # L√≥gica de comunica√ß√£o com a API do Gemini
‚îú‚îÄ‚îÄ olx_service.py        # L√≥gica para recolher dados da API do OLX
‚îú‚îÄ‚îÄ prompt.py             # Armazena e formata os prompts para a IA
‚îú‚îÄ‚îÄ utils.py              # Fun√ß√µes de utilidade (ex: ler ficheiros)
‚îú‚îÄ‚îÄ vercel.json           # Ficheiro de configura√ß√£o para o deploy na Vercel
‚îî‚îÄ‚îÄ requirements.txt      # Lista de depend√™ncias Python do projeto
üöÄ Como Executar Localmente
Siga estes passos para configurar e executar o projeto na sua m√°quina.

1. Pr√©-requisitos
Python 3.9 ou superior

Uma chave de API do Google AI Studio (Gemini)

2. Clonar o Reposit√≥rio
Bash

git clone https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git
cd SEU_REPOSITORIO
3. Criar um Ambiente Virtual e Instalar Depend√™ncias
√â uma boa pr√°tica usar um ambiente virtual para isolar as depend√™ncias do projeto.

Bash

# Criar o ambiente virtual
python -m venv venv

# Ativar o ambiente (Windows)
.\venv\Scripts\activate

# Ativar o ambiente (macOS/Linux)
source venv/bin/activate

# Instalar as bibliotecas necess√°rias
pip install -r requirements.txt
4. Configurar as Chaves de API (Secrets)
Para desenvolvimento local, o Streamlit utiliza um ficheiro secrets.toml.

Crie uma pasta .streamlit na raiz do projeto.

Dentro dela, crie um ficheiro chamado secrets.toml com o seguinte conte√∫do:

Ini, TOML

# .streamlit/secrets.toml
GEMINI_API_KEY = "sua-chave-api-do-gemini-aqui"
5. Executar a Aplica√ß√£o
Com o ambiente virtual ativado, execute o seguinte comando no terminal:

Bash

streamlit run app.py
A aplica√ß√£o ser√° aberta automaticamente no seu navegador. Para a funcionalidade de dados em tempo real, ser√° necess√°rio obter e colar o seu Bearer Token do OLX no campo apropriado na barra lateral.

‚òÅÔ∏è Deploy na Vercel
Este projeto est√° pronto para ser implementado na Vercel.

Fa√ßa o push do seu c√≥digo para um reposit√≥rio no GitHub, GitLab ou Bitbucket.

Configure as Vari√°veis de Ambiente no painel do seu projeto na Vercel. Adicione a GEMINI_API_KEY. O c√≥digo em config.py j√° est√° preparado para ler esta vari√°vel.

Importe o seu projeto na Vercel. A Vercel ir√° detetar automaticamente o ficheiro vercel.json e implementar a aplica√ß√£o.

Nota: Para uma aplica√ß√£o p√∫blica e est√°vel, recomenda-se a "Op√ß√£o A" descrita na nossa conversa: recolher os dados uma vez, guard√°-los num ficheiro .json e modificar o app.py para ler esse ficheiro, em vez de depender de um Bearer Token manual.

```python
print("Modelos dispon√≠veis:")
for m in genai.list_models():
  # Verifica se o modelo suporta o m√©todo 'generateContent'
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

```

models/gemini-2.5-pro-preview-03-25
models/gemini-2.5-flash-preview-05-20
models/gemini-2.5-flash
models/gemini-2.5-flash-lite-preview-06-17
models/gemini-2.5-pro-preview-05-06
models/gemini-2.5-pro-preview-06-05
models/gemini-2.5-pro
models/gemini-2.0-flash-exp
models/gemini-2.0-flash
models/gemini-2.0-flash-001
models/gemini-2.0-flash-lite-001
models/gemini-2.0-flash-lite
models/gemini-2.0-flash-lite-preview-02-05
models/gemini-2.0-flash-lite-preview
models/gemini-2.0-pro-exp
models/gemini-2.0-pro-exp-02-05
models/gemini-exp-1206
models/gemini-2.0-flash-thinking-exp-01-21
models/gemini-2.0-flash-thinking-exp
models/gemini-2.0-flash-thinking-exp-1219
models/gemini-2.5-flash-preview-tts
models/gemini-2.5-pro-preview-tts
models/learnlm-2.0-flash-experimental
models/gemma-3-1b-it
models/gemma-3-4b-it
models/gemma-3-12b-it
models/gemma-3-27b-it
models/gemma-3n-e4b-it
models/gemma-3n-e2b-it
models/gemini-flash-latest
models/gemini-flash-lite-latest
models/gemini-pro-latest
models/gemini-2.5-flash-lite
models/gemini-2.5-flash-image-preview
models/gemini-2.5-flash-preview-09-2025
models/gemini-2.5-flash-lite-preview-09-2025
models/gemini-robotics-er-1.5-preview

```bash 
pip install -r requirements.txt
```
```bash 
streamlit run app.py
```